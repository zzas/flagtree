module {
  func.func @rotary_embedding_siso_kernel(%arg0: memref<?xi8>, %arg1: memref<?xi8>, %arg2: memref<?xf32> {tt.divisibility = 16 : i32, tt.tensor_kind = 1 : i32}, %arg3: memref<?xf32> {tt.divisibility = 16 : i32, tt.tensor_kind = 0 : i32}, %arg4: memref<?xf32> {tt.divisibility = 16 : i32, tt.tensor_kind = 0 : i32}, %arg5: memref<?xf32> {tt.divisibility = 16 : i32, tt.tensor_kind = 0 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32) attributes {SyncBlockLockArgIdx = 0 : i64, WorkspaceArgIdx = 1 : i64, global_kernel = "local", mix_mode = "aiv"} {
    %cst = arith.constant 0.000000e+00 : f32
    %c4 = arith.constant 4 : index
    %c8 = arith.constant 8 : index
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4_i32 = arith.constant 4 : i32
    %c8_i32 = arith.constant 8 : i32
    %0 = arith.muli %arg14, %c8_i32 : i32
    %1 = arith.muli %arg15, %c4_i32 : i32
    scf.for %arg17 = %c0_i32 to %c4_i32 step %c1_i32  : i32 {
      %2 = arith.muli %arg17, %c2_i32 : i32
      %3 = arith.addi %2, %c1_i32 : i32
      %4 = arith.index_cast %0 : i32 to index
      %5 = arith.index_cast %arg6 : i32 to index
      %6 = arith.muli %4, %5 : index
      %7 = arith.index_cast %1 : i32 to index
      %8 = arith.index_cast %arg7 : i32 to index
      %9 = arith.muli %7, %8 : index
      %10 = arith.index_cast %2 : i32 to index
      %11 = arith.addi %6, %10 : index
      %12 = arith.addi %11, %9 : index
      %reinterpret_cast = memref.reinterpret_cast %arg3 to offset: [%12], sizes: [8, 4, 1], strides: [%5, %8, 1] : memref<?xf32> to memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>>
      %alloc = memref.alloc() : memref<8x4x1xf32>
      %13 = arith.addi %4, %c8 : index
      %14 = arith.index_cast %arg9 : i32 to index
      %15 = arith.maxsi %4, %14 : index
      %16 = arith.minsi %13, %15 : index
      %17 = arith.subi %16, %4 : index
      %18 = arith.addi %7, %c4 : index
      %19 = arith.index_cast %arg10 : i32 to index
      %20 = arith.maxsi %7, %19 : index
      %21 = arith.minsi %18, %20 : index
      %22 = arith.subi %21, %7 : index
      %23 = arith.minsi %17, %c8 : index
      %24 = arith.minsi %22, %c4 : index
      %25 = arith.cmpi slt, %23, %c8 : index
      %26 = arith.cmpi slt, %24, %c4 : index
      %27 = arith.ori %25, %26 : i1
      scf.if %27 {
        linalg.fill ins(%cst : f32) outs(%alloc : memref<8x4x1xf32>)
      }
      %subview = memref.subview %reinterpret_cast[0, 0, 0] [%23, %24, 1] [1, 1, 1] : memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>> to memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>>
      %subview_0 = memref.subview %alloc[0, 0, 0] [%23, %24, 1] [1, 1, 1] : memref<8x4x1xf32> to memref<?x?x1xf32, strided<[4, 1, 1]>>
      memref.copy %subview, %subview_0 : memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>> to memref<?x?x1xf32, strided<[4, 1, 1]>>
      %28 = bufferization.to_tensor %alloc restrict writable : memref<8x4x1xf32>
      %29 = arith.index_cast %3 : i32 to index
      %30 = arith.addi %6, %29 : index
      %31 = arith.addi %30, %9 : index
      %reinterpret_cast_1 = memref.reinterpret_cast %arg3 to offset: [%31], sizes: [8, 4, 1], strides: [%5, %8, 1] : memref<?xf32> to memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>>
      %alloc_2 = memref.alloc() : memref<8x4x1xf32>
      scf.if %27 {
        linalg.fill ins(%cst : f32) outs(%alloc_2 : memref<8x4x1xf32>)
      }
      %subview_3 = memref.subview %reinterpret_cast_1[0, 0, 0] [%23, %24, 1] [1, 1, 1] : memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>> to memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>>
      %subview_4 = memref.subview %alloc_2[0, 0, 0] [%23, %24, 1] [1, 1, 1] : memref<8x4x1xf32> to memref<?x?x1xf32, strided<[4, 1, 1]>>
      memref.copy %subview_3, %subview_4 : memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>> to memref<?x?x1xf32, strided<[4, 1, 1]>>
      %32 = bufferization.to_tensor %alloc_2 restrict writable : memref<8x4x1xf32>
      %33 = arith.index_cast %arg8 : i32 to index
      %34 = arith.muli %4, %33 : index
      %35 = arith.addi %34, %10 : index
      %reinterpret_cast_5 = memref.reinterpret_cast %arg4 to offset: [%35], sizes: [8, 1, 1], strides: [%33, 1, 1] : memref<?xf32> to memref<8x1x1xf32, strided<[?, 1, 1], offset: ?>>
      %alloc_6 = memref.alloc() : memref<8x1x1xf32>
      %36 = arith.cmpi slt, %17, %c8 : index
      scf.if %36 {
        linalg.fill ins(%cst : f32) outs(%alloc_6 : memref<8x1x1xf32>)
      }
      %subview_7 = memref.subview %reinterpret_cast_5[0, 0, 0] [%17, 1, 1] [1, 1, 1] : memref<8x1x1xf32, strided<[?, 1, 1], offset: ?>> to memref<?x1x1xf32, strided<[?, 1, 1], offset: ?>>
      %subview_8 = memref.subview %alloc_6[0, 0, 0] [%17, 1, 1] [1, 1, 1] : memref<8x1x1xf32> to memref<?x1x1xf32, strided<[1, 1, 1]>>
      memref.copy %subview_7, %subview_8 : memref<?x1x1xf32, strided<[?, 1, 1], offset: ?>> to memref<?x1x1xf32, strided<[1, 1, 1]>>
      %37 = bufferization.to_tensor %alloc_6 restrict writable : memref<8x1x1xf32>
      %38 = arith.addi %34, %29 : index
      %reinterpret_cast_9 = memref.reinterpret_cast %arg5 to offset: [%38], sizes: [8, 1, 1], strides: [%33, 1, 1] : memref<?xf32> to memref<8x1x1xf32, strided<[?, 1, 1], offset: ?>>
      %alloc_10 = memref.alloc() : memref<8x1x1xf32>
      scf.if %36 {
        linalg.fill ins(%cst : f32) outs(%alloc_10 : memref<8x1x1xf32>)
      }
      %subview_11 = memref.subview %reinterpret_cast_9[0, 0, 0] [%17, 1, 1] [1, 1, 1] : memref<8x1x1xf32, strided<[?, 1, 1], offset: ?>> to memref<?x1x1xf32, strided<[?, 1, 1], offset: ?>>
      %subview_12 = memref.subview %alloc_10[0, 0, 0] [%17, 1, 1] [1, 1, 1] : memref<8x1x1xf32> to memref<?x1x1xf32, strided<[1, 1, 1]>>
      memref.copy %subview_11, %subview_12 : memref<?x1x1xf32, strided<[?, 1, 1], offset: ?>> to memref<?x1x1xf32, strided<[1, 1, 1]>>
      %39 = bufferization.to_tensor %alloc_10 restrict writable : memref<8x1x1xf32>
      %40 = tensor.empty() : tensor<8x4x1xf32>
      %collapsed = tensor.collapse_shape %37 [[0], [1, 2]] : tensor<8x1x1xf32> into tensor<8x1xf32>
      %broadcasted = linalg.broadcast ins(%collapsed : tensor<8x1xf32>) outs(%40 : tensor<8x4x1xf32>) dimensions = [1] 
      %41 = arith.mulf %28, %broadcasted : tensor<8x4x1xf32>
      %collapsed_13 = tensor.collapse_shape %39 [[0], [1, 2]] : tensor<8x1x1xf32> into tensor<8x1xf32>
      %broadcasted_14 = linalg.broadcast ins(%collapsed_13 : tensor<8x1xf32>) outs(%40 : tensor<8x4x1xf32>) dimensions = [1] 
      %42 = arith.mulf %32, %broadcasted_14 : tensor<8x4x1xf32>
      %43 = arith.subf %41, %42 : tensor<8x4x1xf32>
      %44 = arith.mulf %28, %broadcasted_14 : tensor<8x4x1xf32>
      %45 = arith.mulf %32, %broadcasted : tensor<8x4x1xf32>
      %46 = arith.addf %44, %45 : tensor<8x4x1xf32>
      %reinterpret_cast_15 = memref.reinterpret_cast %arg2 to offset: [%12], sizes: [8, 4, 1], strides: [%5, %8, 1] : memref<?xf32> to memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>>
      %extracted_slice = tensor.extract_slice %43[0, 0, 0] [%23, %24, 1] [1, 1, 1] : tensor<8x4x1xf32> to tensor<?x?x1xf32>
      %subview_16 = memref.subview %reinterpret_cast_15[0, 0, 0] [%23, %24, 1] [1, 1, 1] : memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>> to memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>>
      bufferization.materialize_in_destination %extracted_slice in writable %subview_16 : (tensor<?x?x1xf32>, memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>>) -> ()
      %reinterpret_cast_17 = memref.reinterpret_cast %arg2 to offset: [%31], sizes: [8, 4, 1], strides: [%5, %8, 1] : memref<?xf32> to memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>>
      %extracted_slice_18 = tensor.extract_slice %46[0, 0, 0] [%23, %24, 1] [1, 1, 1] : tensor<8x4x1xf32> to tensor<?x?x1xf32>
      %subview_19 = memref.subview %reinterpret_cast_17[0, 0, 0] [%23, %24, 1] [1, 1, 1] : memref<8x4x1xf32, strided<[?, ?, 1], offset: ?>> to memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>>
      bufferization.materialize_in_destination %extracted_slice_18 in writable %subview_19 : (tensor<?x?x1xf32>, memref<?x?x1xf32, strided<[?, ?, 1], offset: ?>>) -> ()
    }
    return
  }
}

